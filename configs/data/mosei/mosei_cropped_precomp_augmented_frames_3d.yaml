class_path: data.datamodules.CMUMOSEIVideoDataModule
init_args:
  data_dir: data
  labels: ['Happiness', 'Sadness', 'Anger', 'Fear', 'Disgust', 'Surprise']
  num_classes: 6
  resize_scale: 180
  label_discretization_threshold: 0.0
  num_mels: 128
  multi_label: true
  crop_face: true
  num_augmented_samples_to_load: 1
  label_type: discrete
  modalities: ['frames_3d']
  transforms:
    train:
      frames_3d:
      - name: aug1
        class_path: torchvision.transforms.Compose
        init_args:
          transforms:
          - class_path: data.transforms.RandomResizedCropVideo
            init_args:
              size: $self.img_size
              scale: [0.8, 1.0]
              ratio: [0.8, 1.2]
          - class_path: torchvision.transforms.RandomHorizontalFlip
          - class_path: pytorchvideo.transforms.Normalize
            init_args:
              mean: $self.mean['frames_3d']
              std: $self.std['frames_3d']
      - name: aug2
        class_path: torchvision.transforms.Compose
        init_args:
          transforms:
          - class_path: data.transforms.RandomResizedCropVideo
            init_args:
              size: $self.img_size
              scale: [0.8, 1.0]
              ratio: [0.8, 1.2]
          - class_path: torchvision.transforms.RandomHorizontalFlip
          - class_path: pytorchvideo.transforms.Normalize
            init_args:
              mean: $self.mean['frames_3d']
              std: $self.std['frames_3d']
      - name: aug3
        class_path: torchvision.transforms.Compose
        init_args:
          transforms:
          - class_path: data.transforms.RandomResizedCropVideo
            init_args:
              size: $self.img_size
              scale: [0.8, 1.0]
              ratio: [0.8, 1.2]
          - class_path: torchvision.transforms.RandomHorizontalFlip
          - class_path: pytorchvideo.transforms.Normalize
            init_args:
              mean: $self.mean['frames_3d']
              std: $self.std['frames_3d']
      - name: aug4
        class_path: torchvision.transforms.Compose
        init_args:
          transforms:
          - class_path: data.transforms.RandomResizedCropVideo
            init_args:
              size: $self.img_size
              scale: [0.8, 1.0]
              ratio: [0.8, 1.2]
          - class_path: torchvision.transforms.RandomHorizontalFlip
          - class_path: pytorchvideo.transforms.Normalize
            init_args:
              mean: $self.mean['frames_3d']
              std: $self.std['frames_3d']
      - name: aug5
        class_path: torchvision.transforms.Compose
        init_args:
          transforms:
          - class_path: data.transforms.RandomResizedCropVideo
            init_args:
              size: $self.img_size
              scale: [0.8, 1.0]
              ratio: [0.8, 1.2]
          - class_path: torchvision.transforms.RandomHorizontalFlip
          - class_path: pytorchvideo.transforms.Normalize
            init_args:
              mean: $self.mean['frames_3d']
              std: $self.std['frames_3d']
      - name: aug6
        class_path: torchvision.transforms.Compose
        init_args:
          transforms:
          - class_path: data.transforms.RandomResizedCropVideo
            init_args:
              size: $self.img_size
              scale: [0.8, 1.0]
              ratio: [0.8, 1.2]
          - class_path: torchvision.transforms.RandomHorizontalFlip
          - class_path: pytorchvideo.transforms.Normalize
            init_args:
              mean: $self.mean['frames_3d']
              std: $self.std['frames_3d']
      - name: aug7
        class_path: torchvision.transforms.Compose
        init_args:
          transforms:
          - class_path: data.transforms.RandomResizedCropVideo
            init_args:
              size: $self.img_size
              scale: [0.8, 1.0]
              ratio: [0.8, 1.2]
          - class_path: torchvision.transforms.RandomHorizontalFlip
          - class_path: pytorchvideo.transforms.Normalize
            init_args:
              mean: $self.mean['frames_3d']
              std: $self.std['frames_3d']
      - name: aug8
        class_path: torchvision.transforms.Compose
        init_args:
          transforms:
          - class_path: data.transforms.RandomResizedCropVideo
            init_args:
              size: $self.img_size
              scale: [0.8, 1.0]
              ratio: [0.8, 1.2]
          - class_path: torchvision.transforms.RandomHorizontalFlip
          - class_path: pytorchvideo.transforms.Normalize
            init_args:
              mean: $self.mean['frames_3d']
              std: $self.std['frames_3d']
      - name: aug9
        class_path: torchvision.transforms.Compose
        init_args:
          transforms:
          - class_path: data.transforms.RandomResizedCropVideo
            init_args:
              size: $self.img_size
              scale: [0.8, 1.0]
              ratio: [0.8, 1.2]
          - class_path: torchvision.transforms.RandomHorizontalFlip
          - class_path: pytorchvideo.transforms.Normalize
            init_args:
              mean: $self.mean['frames_3d']
              std: $self.std['frames_3d']
      - name: aug10
        class_path: torchvision.transforms.Compose
        init_args:
          transforms:
          - class_path: data.transforms.RandomResizedCropVideo
            init_args:
              size: $self.img_size
              scale: [0.8, 1.0]
              ratio: [0.8, 1.2]
          - class_path: torchvision.transforms.RandomHorizontalFlip
          - class_path: pytorchvideo.transforms.Normalize
            init_args:
              mean: $self.mean['frames_3d']
              std: $self.std['frames_3d']
    val:
      frames_3d:
        class_path: torchvision.transforms.Compose
        init_args:
          transforms:
          - class_path: data.transforms.ResizeVideo
            init_args:
              size: $[self.img_size[0], self.img_size[1]]
          - class_path: pytorchvideo.transforms.Normalize
            init_args:
              mean: $self.mean['frames_3d']
              std: $self.std['frames_3d']
    test:
      frames_3d:
        class_path: torchvision.transforms.Compose
        init_args:
          transforms:
          - class_path: data.transforms.ResizeVideo
            init_args:
              size: $[self.img_size[0], self.img_size[1]]
          - class_path: pytorchvideo.transforms.Normalize
            init_args:
              mean: $self.mean['frames_3d']
              std: $self.std['frames_3d']
  feature_precomputation_config:
    frames_3d:
      target_fps: 16
      window_size: 16
      window_stride: 16